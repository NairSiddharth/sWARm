{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367ud8k6u6t",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORCE MODULE RELOAD - FIX JUPYTER CACHING ISSUE (MUST BE FIRST!)\n",
    "import sys \n",
    "\n",
    "# Remove defensive_metrics from cache and reload\n",
    "if 'modules.defensive_metrics' in sys.modules:\n",
    "    print(\"Removing cached defensive_metrics module...\")\n",
    "    del sys.modules['modules.defensive_metrics']\n",
    "\n",
    "# Remove cleanedDataParser from cache and reload  \n",
    "if 'cleanedDataParser' in sys.modules:\n",
    "    print(\"Removing cached cleanedDataParser module...\")\n",
    "    del sys.modules['cleanedDataParser']\n",
    "\n",
    "# Remove any other related modules\n",
    "modules_to_remove = [key for key in sys.modules.keys() if 'modules.' in key]\n",
    "for module in modules_to_remove:\n",
    "    print(f\"Removing cached {module} module...\")\n",
    "    del sys.modules[module]\n",
    "\n",
    "print(\"All cached modules removed! Fresh imports will now load the latest fixes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "syca60aanj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL-IN-ONE FULLY OPTIMIZED COMPLETE PIPELINE\n",
    "\n",
    "# ===== IMPORTS =====\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import importlib\n",
    "from modularized_data_parser import *\n",
    "from modules.two_way_players import get_cleaned_two_way_data\n",
    "from modules.modeling import (\n",
    "    ModelResults, create_keras_model, print_metrics,\n",
    "    run_basic_regressions, run_advanced_models, \n",
    "    run_nonlinear_models, run_neural_network,\n",
    "    select_best_models_by_category, apply_proper_war_adjustments\n",
    ")\n",
    "from modules.park_factors import (\n",
    "    calculate_park_factors, \n",
    "    apply_enhanced_hitter_park_adjustments, \n",
    "    apply_enhanced_pitcher_park_adjustments\n",
    ")\n",
    "from modules.name_mapping_caching import create_name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wewfzuo3sd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def plot_consolidated_model_comparison(model_results, model_names=None, show_residuals=True, show_metrics=True):\n",
    "    \"\"\"\n",
    "    Consolidated model comparison system that replaces individual print_metrics graphs.\n",
    "    Creates unified visualizations with selectable traces for easy comparison.\n",
    "\n",
    "    Args:\n",
    "        model_results: Your ModelResults object\n",
    "        model_names: List of models to compare (None = auto-select best)\n",
    "        show_residuals: Whether to include residual analysis plots\n",
    "        show_metrics: Whether to include scatter plot comparisons\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with analysis results for each model\n",
    "    \"\"\"\n",
    "    if model_names is None:\n",
    "        model_names = select_best_models_by_category(model_results)\n",
    "        print(f\"üéØ Auto-selected models for comparison: {[m.upper() for m in model_names]}\")\n",
    "\n",
    "    print(\"\\nüìä CONSOLIDATED MODEL COMPARISON SYSTEM\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"üîç Replacing individual graphs with unified selectable trace visualizations...\")\n",
    "\n",
    "    # Collect all data for consolidated visualizations\n",
    "    all_data = []\n",
    "    model_stats = {}\n",
    "\n",
    "    for model_name in model_names:\n",
    "        model_stats[model_name] = {}\n",
    "\n",
    "        for player_type in ['hitter', 'pitcher']:\n",
    "            for metric in ['war', 'warp']:\n",
    "                key = f\"{model_name}_{player_type}_{metric}\"\n",
    "                if key in model_results.results:\n",
    "                    data = model_results.results[key]\n",
    "\n",
    "                    if len(data['y_true']) > 0:\n",
    "                        y_true = np.array(data['y_true'])\n",
    "                        y_pred = np.array(data['y_pred'])\n",
    "                        residuals = y_true - y_pred\n",
    "\n",
    "                        # Calculate comprehensive statistics\n",
    "                        rmse = np.sqrt(np.mean(residuals**2))\n",
    "                        mae = np.mean(np.abs(residuals))\n",
    "                        r2 = 1 - (np.sum(residuals**2) / np.sum((y_true - np.mean(y_true))**2))\n",
    "\n",
    "                        # Store statistics\n",
    "                        model_stats[model_name][f\"{player_type}_{metric}\"] = {\n",
    "                            'rmse': rmse,\n",
    "                            'mae': mae,\n",
    "                            'r2': r2,\n",
    "                            'count': len(y_true)\n",
    "                        }\n",
    "\n",
    "                        # Add to plotting data\n",
    "                        for i in range(len(residuals)):\n",
    "                            all_data.append({\n",
    "                                'Model': model_name.title(),\n",
    "                                'PlayerType': player_type.title(),\n",
    "                                'Metric': metric.upper(),\n",
    "                                'Category': f\"{player_type.title()} {metric.upper()}\",\n",
    "                                'Actual': y_true[i],\n",
    "                                'Predicted': y_pred[i],\n",
    "                                'Residual': residuals[i],\n",
    "                                'Player': data['player_names'][i] if 'player_names' in data else f\"Player_{i}\"\n",
    "                            })\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"‚ùå No data available for consolidated comparison\")\n",
    "        return {}\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # 1. CONSOLIDATED SCATTER PLOTS WITH SELECTABLE TRACES\n",
    "    if show_metrics:\n",
    "        print(\"\\nCreating consolidated prediction accuracy plots...\")\n",
    "\n",
    "        fig_scatter = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=['Hitter WAR', 'Hitter WARP', 'Pitcher WAR', 'Pitcher WARP'],\n",
    "            vertical_spacing=0.1,\n",
    "            horizontal_spacing=0.1\n",
    "        )\n",
    "\n",
    "        colors = px.colors.qualitative.Set1\n",
    "\n",
    "        for i, category in enumerate(['Hitter WAR', 'Hitter WARP', 'Pitcher WAR', 'Pitcher WARP']):\n",
    "            cat_data = df[df['Category'] == category]\n",
    "\n",
    "            row = (i // 2) + 1\n",
    "            col = (i % 2) + 1\n",
    "\n",
    "            for j, model in enumerate(cat_data['Model'].unique()):\n",
    "                model_data = cat_data[cat_data['Model'] == model]\n",
    "\n",
    "                fig_scatter.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=model_data['Actual'],\n",
    "                        y=model_data['Predicted'],\n",
    "                        mode='markers',\n",
    "                        name=f\"{model} {category}\",\n",
    "                        marker=dict(color=colors[j % len(colors)], size=6, opacity=0.7),\n",
    "                        text=model_data['Player'],\n",
    "                        hovertemplate=\"<b>%{text}</b><br>\" +\n",
    "                                      \"Actual: %{x:.3f}<br>\" +\n",
    "                                      \"Predicted: %{y:.3f}<br>\" +\n",
    "                                      f\"Model: {model}<br>\" +\n",
    "                                      \"<extra></extra>\",\n",
    "                        showlegend=(i == 0)  # Only show legend for first subplot\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "\n",
    "                # Add perfect prediction line\n",
    "                if j == 0:  # Only add once per subplot\n",
    "                    min_val = min(model_data['Actual'].min(), model_data['Predicted'].min())\n",
    "                    max_val = max(model_data['Actual'].max(), model_data['Predicted'].max())\n",
    "\n",
    "                    fig_scatter.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=[min_val, max_val],\n",
    "                            y=[min_val, max_val],\n",
    "                            mode='lines',\n",
    "                            line=dict(dash='dash', color='red', width=2),\n",
    "                            name='Perfect Prediction',\n",
    "                            showlegend=(i == 0)\n",
    "                        ),\n",
    "                        row=row, col=col\n",
    "                    )\n",
    "\n",
    "        fig_scatter.update_layout(\n",
    "            title=\"Consolidated Model Comparison: Prediction Accuracy (Click Legend to Toggle)\",\n",
    "            height=800,\n",
    "            width=1200,\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"center\", x=0.5)\n",
    "        )\n",
    "\n",
    "        fig_scatter.show()\n",
    "\n",
    "    # 2. CONSOLIDATED RESIDUAL ANALYSIS\n",
    "    if show_residuals:\n",
    "        print(\"\\nüîç Creating consolidated residual analysis...\")\n",
    "\n",
    "        fig_residuals = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=['Residuals vs Fitted', 'Residual Distributions', 'Q-Q Plot', 'Model Performance'],\n",
    "            specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "                   [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "        )\n",
    "\n",
    "        # Residuals vs Fitted\n",
    "        for j, model in enumerate(df['Model'].unique()):\n",
    "            model_data = df[df['Model'] == model]\n",
    "\n",
    "            fig_residuals.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=model_data['Predicted'],\n",
    "                    y=model_data['Residual'],\n",
    "                    mode='markers',\n",
    "                    name=f\"{model} Residuals\",\n",
    "                    marker=dict(color=colors[j % len(colors)], size=4, opacity=0.6),\n",
    "                    showlegend=True\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "\n",
    "        # Add horizontal line at y=0\n",
    "        fig_residuals.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", row=1, col=1)\n",
    "\n",
    "        # Residual Distributions\n",
    "        for j, model in enumerate(df['Model'].unique()):\n",
    "            model_data = df[df['Model'] == model]\n",
    "\n",
    "            fig_residuals.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=model_data['Residual'],\n",
    "                    name=f\"{model} Distribution\",\n",
    "                    opacity=0.7,\n",
    "                    nbinsx=30,\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "\n",
    "        # Q-Q Plot (simplified - one model for clarity)\n",
    "        if len(df['Model'].unique()) > 0:\n",
    "            best_model = df['Model'].unique()[0]\n",
    "            best_data = df[df['Model'] == best_model]\n",
    "            residuals = best_data['Residual'].values\n",
    "\n",
    "            sorted_residuals = np.sort(residuals)\n",
    "            n = len(sorted_residuals)\n",
    "            theoretical_quantiles = stats.norm.ppf(np.linspace(0.01, 0.99, n))\n",
    "\n",
    "            fig_residuals.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=theoretical_quantiles,\n",
    "                    y=sorted_residuals,\n",
    "                    mode='markers',\n",
    "                    name=f\"{best_model} Q-Q\",\n",
    "                    marker=dict(size=4),\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "\n",
    "            # Theoretical line\n",
    "            slope = np.std(residuals)\n",
    "            intercept = np.mean(residuals)\n",
    "            line_min, line_max = min(theoretical_quantiles), max(theoretical_quantiles)\n",
    "\n",
    "            fig_residuals.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=[line_min, line_max],\n",
    "                    y=[intercept + slope * line_min, intercept + slope * line_max],\n",
    "                    mode='lines',\n",
    "                    line=dict(color='red', dash='dash'),\n",
    "                    name='Normal Line',\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "\n",
    "        # Model Performance Comparison\n",
    "        models = list(model_stats.keys())\n",
    "        metrics = ['R¬≤', 'RMSE', 'MAE']\n",
    "\n",
    "        for metric_name in metrics:\n",
    "            metric_values = []\n",
    "            for model in models:\n",
    "                # Average across all model variants\n",
    "                values = []\n",
    "                for key, model_stat_data in model_stats[model].items():\n",
    "                    if metric_name == 'R¬≤':\n",
    "                        values.append(model_stat_data['r2'])\n",
    "                    elif metric_name == 'RMSE':\n",
    "                        values.append(model_stat_data['rmse'])\n",
    "                    elif metric_name == 'MAE':\n",
    "                        values.append(model_stat_data['mae'])\n",
    "\n",
    "                metric_values.append(np.mean(values) if values else 0)\n",
    "\n",
    "            fig_residuals.add_trace(\n",
    "                go.Bar(\n",
    "                    x=models,\n",
    "                    y=metric_values,\n",
    "                    name=metric_name,\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=2\n",
    "            )\n",
    "\n",
    "        fig_residuals.update_layout(\n",
    "            title=\"Consolidated Residual Analysis (Click Legend to Toggle Models)\",\n",
    "            height=800,\n",
    "            width=1200,\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"center\", x=0.5)\n",
    "        )\n",
    "\n",
    "        fig_residuals.show()\n",
    "\n",
    "    # 3. COMPREHENSIVE STATISTICAL SUMMARY\n",
    "    print(\"\\nCONSOLIDATED MODEL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    for model_name in model_names:\n",
    "        if model_name in model_stats:\n",
    "            print(f\"\\nü§ñ {model_name.upper()} MODEL:\")\n",
    "\n",
    "            total_predictions = sum(model_stat_data['count'] for model_stat_data in model_stats[model_name].values())\n",
    "            avg_r2 = np.mean([model_stat_data['r2'] for model_stat_data in model_stats[model_name].values()])\n",
    "            avg_rmse = np.mean([model_stat_data['rmse'] for model_stat_data in model_stats[model_name].values()])\n",
    "            avg_mae = np.mean([model_stat_data['mae'] for model_stat_data in model_stats[model_name].values()])\n",
    "\n",
    "            print(f\"   üìä Overall Performance:\")\n",
    "            print(f\"      ‚Ä¢ Total Predictions: {total_predictions}\")\n",
    "            print(f\"      ‚Ä¢ Average R¬≤: {avg_r2:.4f}\")\n",
    "            print(f\"      ‚Ä¢ Average RMSE: {avg_rmse:.4f}\")\n",
    "            print(f\"      ‚Ä¢ Average MAE: {avg_mae:.4f}\")\n",
    "\n",
    "            print(f\"   üìà By Category:\")\n",
    "            for key, model_stat_data in model_stats[model_name].items():\n",
    "                category = key.replace('_', ' ').title()\n",
    "                print(f\"      ‚Ä¢ {category}: R¬≤={model_stat_data['r2']:.4f}, RMSE={model_stat_data['rmse']:.4f}, Count={model_stat_data['count']}\")\n",
    "\n",
    "    return model_stats\n",
    "\n",
    "def plot_comprehensive_residual_analysis(model_results, model_names=None, player_type=\"both\", metric=\"both\"):\n",
    "    \"\"\"\n",
    "    Comprehensive residual plot comparison system for ML model diagnostics.\n",
    "\n",
    "    This function creates multiple residual visualizations to diagnose model performance:\n",
    "    1. Residuals vs Fitted Values (heteroscedasticity detection)\n",
    "    2. Q-Q plots (normality assessment)\n",
    "    3. Residual distribution histograms\n",
    "    4. Scale-Location plots (variance homogeneity)\n",
    "    5. Model comparison summary statistics\n",
    "\n",
    "    Args:\n",
    "        model_results: Your ModelResults object\n",
    "        model_names: List of models to compare (None = auto-select best)\n",
    "        player_type: 'hitter', 'pitcher', or 'both'\n",
    "        metric: 'war', 'warp', or 'both'\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with residual analysis results for each model\n",
    "    \"\"\"\n",
    "    # Use the new consolidated system\n",
    "    return plot_consolidated_model_comparison(model_results, model_names, show_residuals=True, show_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "py3w4mqwgl",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(title, y_true, y_pred, player_names=None):\n",
    "    \"\"\"Enhanced plot with player names in hover tooltips\"\"\"\n",
    "    if player_names is None:\n",
    "        player_names = [f\"Player_{i}\" for i in range(len(y_true))]\n",
    "    \n",
    "    # Calculate errors for additional hover info\n",
    "    errors = np.array(y_pred) - np.array(y_true)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=y_true, \n",
    "        y=y_pred,\n",
    "        mode='markers',\n",
    "        marker=dict(size=8, opacity=0.7),\n",
    "        text=player_names,\n",
    "        customdata=np.column_stack((errors, y_true, y_pred)),\n",
    "        hovertemplate=\"<b>%{text}</b><br>\" +\n",
    "                      \"Actual WAR: %{customdata[1]:.3f}<br>\" +\n",
    "                      \"Predicted WAR: %{customdata[2]:.3f}<br>\" +\n",
    "                      \"Error: %{customdata[0]:.3f}<br>\" +\n",
    "                      \"<extra></extra>\",\n",
    "        name='Predictions'\n",
    "    ))\n",
    "    \n",
    "    # Add perfect prediction line\n",
    "    min_val = min(min(y_true), min(y_pred))\n",
    "    max_val = max(max(y_true), max(y_pred))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[min_val, max_val], \n",
    "        y=[min_val, max_val],\n",
    "        mode='lines',\n",
    "        line=dict(dash='dash', color='red'),\n",
    "        name='Perfect Prediction'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Actual WAR\",\n",
    "        yaxis_title=\"Predicted WAR\",\n",
    "        template='plotly_white',\n",
    "        width=600,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation loss over epochs\"\"\"\n",
    "    if hasattr(history, 'history'):\n",
    "        # Keras history object\n",
    "        loss = history.history.get('loss', [])\n",
    "        val_loss = history.history.get('val_loss', [])\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        epochs = list(range(1, len(loss) + 1))\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=epochs,\n",
    "            y=loss,\n",
    "            mode='lines',\n",
    "            name='Training Loss',\n",
    "            line=dict(color='blue')\n",
    "        ))\n",
    "        \n",
    "        if val_loss:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=epochs,\n",
    "                y=val_loss,\n",
    "                mode='lines',\n",
    "                name='Validation Loss',\n",
    "                line=dict(color='red')\n",
    "            ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='Training History',\n",
    "            xaxis_title='Epoch',\n",
    "            yaxis_title='Loss',\n",
    "            template='plotly_white'\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No training history available\")\n",
    "\n",
    "print(\"‚úÖ Utility functions loaded: plot_results, plot_training_history (print_metrics from module)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eov0fjfun9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MODEL RESULTS CLASS =====\n",
    "# Import ModelResults from the modeling module\n",
    "model_results = ModelResults()\n",
    "\n",
    "print(\"‚úÖ ModelResults class loaded from modules/modeling.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0q08v371840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DEMONSTRATE NEW COMPREHENSIVE FANGRAPHS INTEGRATION =====\n",
    "try:\n",
    "    print(\"üöÄ TESTING COMPREHENSIVE FANGRAPHS INTEGRATION SYSTEM\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Test the new comprehensive system\n",
    "    from modularized_data_parser import demonstrate_comprehensive_system\n",
    "    demonstrate_comprehensive_system()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error demonstrating comprehensive system: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "def data_preparation():\n",
    "    \"\"\"\n",
    "    FULLY ENHANCED data preparation with ALL missing improvements integrated:\n",
    "    - SUPERIOR name mapping with index-based duplicate handling (from fixed_enhanced_mapping.py)\n",
    "    - Performance optimizations (from optimized_name_matching.py)\n",
    "    - Enhanced conflict resolution (from multiple_matches_handling.py)\n",
    "    - Neural network-safe data cleaning (from complete_fix_integration.py)\n",
    "    - ENHANCED BASERUNNING with run expectancy matrix and situational values\n",
    "    - Stronger park factor effects\n",
    "    - True 2-way player fix with team verification\n",
    "    - Enhanced defensive system with OAA integration and framing\n",
    "    - FIXED: Load park factors ONCE to prevent repetitive loading\n",
    "    - EXPANDED: Yearly BP data (2016-2024 hitters, 2016-2024 pitchers) \n",
    "    - NEW: Comprehensive FanGraphs integration with 50+ features per player\n",
    "    - NEW: Season information capture for multi-year modeling\n",
    "    \"\"\"\n",
    "    print(\"=== FULLY ENHANCED DATA PREPARATION WITH COMPREHENSIVE FANGRAPHS INTEGRATION ===\")\n",
    "    hitter_data = clean_sorted_hitter()\n",
    "    hitter_pred_data = clean_yearly_warp_hitter()  # EXPANDED: 6,410 player-seasons (2016-2024) vs 463 (2021 only)\n",
    "    pitcher_data = clean_sorted_pitcher()\n",
    "    pitcher_pred_data = clean_yearly_warp_pitcher()  # EXPANDED: ~5,000+ player-seasons (2016-2024) vs 472 (2021 only)\n",
    "    war_values = clean_war()\n",
    "    \n",
    "    # Load ENHANCED baserunning system with run expectancy\n",
    "    print(\"Loading ENHANCED baserunning system with run expectancy...\")\n",
    "    enhanced_baserunning_values = calculate_enhanced_baserunning_values()\n",
    "    print(f\"Enhanced baserunning values: {len(enhanced_baserunning_values)} players\")\n",
    "    \n",
    "    # Load enhanced defensive system with OAA integration and framing\n",
    "    print(\"Loading enhanced defensive system...\")\n",
    "    enhanced_defensive_values = clean_enhanced_defensive_players()\n",
    "    print(f\"Enhanced defensive values: {len(enhanced_defensive_values)} player-seasons\")\n",
    "    \n",
    "    # CRITICAL FIX: Load park factors ONCE instead of recalculating for each player\n",
    "    print(\"Loading park factors ONCE (fixes repetitive loading)...\")\n",
    "    park_factors = calculate_park_factors()\n",
    "    print(f\"Loaded park factors for {len(park_factors)} stadiums\")\n",
    "\n",
    "    # Get comprehensive two-way player analysis (replaces 15+ lines of manual logic)\n",
    "    print(\"Identifying true 2-way players using MLB criteria...\")\n",
    "    two_way_analysis = get_cleaned_two_way_data()\n",
    "\n",
    "    # Extract for backward compatibility with existing notebook logic\n",
    "    official_two_way_players = two_way_analysis['two_way_players']\n",
    "    two_way_players = set()\n",
    "\n",
    "    # Convert module data to simple name set (maintains compatibility)\n",
    "    for player_key, data in official_two_way_players.items():\n",
    "        player_name = player_key.rsplit('_', 1)[0]  # Remove year suffix\n",
    "        two_way_players.add(player_name)\n",
    "\n",
    "    # Enhanced reporting using module data\n",
    "    print(f\"True 2-way players found:\")\n",
    "    for player_key, data in official_two_way_players.items():\n",
    "        player_name, year = player_key.rsplit('_', 1)\n",
    "        print(f\"  {player_name} ({year}): Hitter WARP={data['hitting_warp']:.2f}, Pitcher WARP={data['pitching_warp']:.2f}\")\n",
    "\n",
    "    print(f\"Loaded data - Hitters: {len(hitter_data)}, WARP hitters: {len(hitter_pred_data)}, WAR: {len(war_values)}\")\n",
    "    print(f\"Enhanced baserunning values: {len(enhanced_baserunning_values)}\")\n",
    "\n",
    "    print(\"Creating SUPERIOR name mappings with index-based duplicate handling...\")\n",
    "    # CRITICAL IMPROVEMENT: Use optimized index-based mapping that handles duplicates correctly\n",
    "    warp_to_war_map = create_optimized_name_mapping_with_indices(hitter_pred_data, war_values)\n",
    "    \n",
    "    # For hitter stats, use traditional mapping as it works well\n",
    "    warp_to_hitter_map = create_name_mapping(hitter_pred_data['Name'].tolist(), hitter_data['Hitters'].tolist())\n",
    "\n",
    "    hitter_stats = hitter_data\n",
    "    x_warp, y_warp, x_war, y_war = [], [], [], []\n",
    "    hitter_names_warp, hitter_names_war = [], []\n",
    "    # NEW: Season tracking for multi-year modeling\n",
    "    hitter_seasons_warp, hitter_seasons_war = [], []\n",
    "\n",
    "    for index, row in hitter_pred_data.iterrows():\n",
    "        warp_name = row['Name']\n",
    "        team = row['Team']\n",
    "        # NEW: Extract season information\n",
    "        season = row.get('Year', row.get('Season', 2021))  # Try Year first, then Season, default 2021\n",
    "        \n",
    "        hitter_match = warp_to_hitter_map.get(warp_name)\n",
    "        if hitter_match:\n",
    "            player_stats = hitter_stats[hitter_stats['Hitters'] == hitter_match]\n",
    "            if not player_stats.empty:\n",
    "                stats = player_stats[['K','BB','AVG','OBP','SLG']].values.flatten().tolist()\n",
    "                \n",
    "                # Use ENHANCED baserunning values with run expectancy\n",
    "                enhanced_baserunning_val = enhanced_baserunning_values.get(warp_name, 0.0)\n",
    "                stats.append(enhanced_baserunning_val)\n",
    "                \n",
    "                # Apply ENHANCED park factor adjustments with stronger effects (FIXED: Pass park_factors)\n",
    "                park_adjusted_stats = apply_enhanced_hitter_park_adjustments(\n",
    "                    {'AVG': stats[2], 'OBP': stats[3], 'SLG': stats[4]}, warp_name, team, park_factors)\n",
    "                \n",
    "                # Replace original stats with park-adjusted ones if available\n",
    "                if 'AVG_park_adj' in park_adjusted_stats:\n",
    "                    stats[2] = park_adjusted_stats['AVG_park_adj']\n",
    "                    stats[3] = park_adjusted_stats['OBP_park_adj'] \n",
    "                    stats[4] = park_adjusted_stats['SLG_park_adj']\n",
    "                \n",
    "                # Use enhanced defensive system - try multiple possible keys for the player\n",
    "                defensive_val = 0  # Default value\n",
    "                player_name_clean = hitter_match.replace(' ', '').replace('.', '')\n",
    "                \n",
    "                # Try to find defensive value using different key formats\n",
    "                possible_keys = []\n",
    "                for year in [2016, 2017, 2018, 2019, 2020, 2021]:\n",
    "                    for team_abbr in ['BOS', 'NYY', 'TB', 'TOR', 'BAL', 'CLE', 'DET', 'KC', 'MIN', 'CWS', \n",
    "                                'HOU', 'LAA', 'OAK', 'SEA', 'TEX', 'ATL', 'MIA', 'NYM', 'PHI', 'WSN',\n",
    "                                'CHC', 'CIN', 'MIL', 'PIT', 'STL', 'ARI', 'COL', 'LAD', 'SD', 'SF']:\n",
    "                        possible_keys.extend([\n",
    "                            f\"{hitter_match}_{team_abbr}_{year}\",\n",
    "                            f\"{player_name_clean}_{team_abbr}_{year}\",\n",
    "                            f\"{hitter_match.split()[0]}_{team_abbr}_{year}\",  # First name only\n",
    "                        ])\n",
    "                \n",
    "                # Find best match for defensive value\n",
    "                for key in possible_keys:\n",
    "                    if key in enhanced_defensive_values:\n",
    "                        defensive_val = enhanced_defensive_values[key].get('enhanced_def_value', 0)\n",
    "                        break\n",
    "                \n",
    "                stats.append(defensive_val)  # Enhanced defensive value with OAA integration\n",
    "                \n",
    "                x_warp.append(stats)\n",
    "                y_warp.append(row['WARP'])\n",
    "                hitter_names_warp.append(warp_name)\n",
    "                hitter_seasons_warp.append(season)  # NEW: Store season\n",
    "                \n",
    "                # CRITICAL: Use INDEX-based mapping for WAR targets (handles duplicates correctly)\n",
    "                if warp_name in warp_to_war_map:\n",
    "                    target_idx = warp_to_war_map[warp_name]  # Get INDEX not name\n",
    "                    war_row = war_values.iloc[target_idx]    # Use index to get correct row\n",
    "                    total_war = war_row['Total WAR']\n",
    "                    \n",
    "                    # 2-WAY PLAYER FIX: Only apply to TRUE 2-way players (same team)\n",
    "                    if warp_name in two_way_players:\n",
    "                        # For 2-way players, use hitting component only (Total - Primary)\n",
    "                        primary_war = war_row.get('Primary WAR', 0)\n",
    "                        if primary_war is not None and primary_war != 0:\n",
    "                            hitting_war = total_war - primary_war  # Hitting + fielding + baserunning\n",
    "                            print(f\"  TRUE 2-way player {warp_name}: Total WAR {total_war:.2f} -> Hitting WAR {hitting_war:.2f}\")\n",
    "                            target_war = hitting_war\n",
    "                        else:\n",
    "                            target_war = total_war  # Fallback if no Primary WAR\n",
    "                    else:\n",
    "                        # Single-role hitters use Total WAR (which should be hitting-only)\n",
    "                        target_war = total_war\n",
    "                    \n",
    "                    x_war.append(stats)\n",
    "                    y_war.append(target_war)\n",
    "                    hitter_names_war.append(warp_name)\n",
    "                    hitter_seasons_war.append(season)  # NEW: Store season\n",
    "\n",
    "    # CRITICAL: Use enhanced data cleaning for neural networks\n",
    "    print(\"Cleaning data with enhanced neural network-safe algorithms...\")\n",
    "    x_warp, y_warp = validate_and_clean_data_enhanced(x_warp, y_warp)\n",
    "    x_war, y_war = validate_and_clean_data_enhanced(x_war, y_war)\n",
    "\n",
    "    print(f\"Successfully matched {len(x_warp)} hitters with 7 features:\")\n",
    "    print(f\"  - 5 hitting stats (with park adjustments)\")\n",
    "    print(f\"  - Enhanced baserunning (run expectancy + situational)\")\n",
    "    print(f\"  - Enhanced defense (OAA integration + framing)\")\n",
    "    print(f\"WAR target range after enhanced cleaning: {min(y_war):.2f} to {max(y_war):.2f}\")\n",
    "\n",
    "    # Pitcher processing with enhanced mapping and park adjustments (FIXED: Pass park_factors)\n",
    "    pitcher_warp_to_main = create_name_mapping(pitcher_pred_data['Name'].tolist(), pitcher_data['Pitchers'].tolist())\n",
    "    pitcher_warp_to_war = create_optimized_name_mapping_with_indices(pitcher_pred_data, war_values)\n",
    "    pitcher_stats = pitcher_data\n",
    "\n",
    "    a_warp, b_warp, a_war, b_war = [], [], [], []\n",
    "    pitcher_names_warp, pitcher_names_war = [], []\n",
    "    # NEW: Season tracking for pitchers too\n",
    "    pitcher_seasons_warp, pitcher_seasons_war = [], []\n",
    "\n",
    "    for index, row in pitcher_pred_data.iterrows():\n",
    "        warp_name = row['Name']\n",
    "        team = row['Team']\n",
    "        # NEW: Extract season information  \n",
    "        season = row.get('Year', row.get('Season', 2021))\n",
    "        \n",
    "        pitcher_match = pitcher_warp_to_main.get(warp_name)\n",
    "        if pitcher_match:\n",
    "            player_stats = pitcher_stats[pitcher_stats['Pitchers'] == pitcher_match]\n",
    "            if not player_stats.empty:\n",
    "                stats = player_stats[['IP','BB','K','HR','ERA']].values.flatten().tolist()\n",
    "                \n",
    "                # Apply enhanced park adjustments for pitchers (FIXED: Pass park_factors)\n",
    "                park_adjusted_stats = apply_enhanced_pitcher_park_adjustments(\n",
    "                    {'ERA': stats[4]}, warp_name, team, park_factors)\n",
    "                if 'ERA_park_adj' in park_adjusted_stats:\n",
    "                    stats[4] = park_adjusted_stats['ERA_park_adj']\n",
    "                \n",
    "                a_warp.append(stats)\n",
    "                b_warp.append(row['WARP'])\n",
    "                pitcher_names_warp.append(warp_name)\n",
    "                pitcher_seasons_warp.append(season)  # NEW: Store season\n",
    "                \n",
    "                # Use index-based mapping for pitchers too\n",
    "                if warp_name in pitcher_warp_to_war:\n",
    "                    target_idx = pitcher_warp_to_war[warp_name]\n",
    "                    war_row = war_values.iloc[target_idx]\n",
    "                    if 'Primary WAR' in war_row:\n",
    "                        # Primary WAR is already the pitching component - no fix needed\n",
    "                        a_war.append(stats)\n",
    "                        b_war.append(war_row['Primary WAR'])\n",
    "                        pitcher_names_war.append(warp_name)\n",
    "                        pitcher_seasons_war.append(season)  # NEW: Store season\n",
    "\n",
    "    # Enhanced data cleaning for pitchers too\n",
    "    a_warp, b_warp = validate_and_clean_data_enhanced(a_warp, b_warp)\n",
    "    a_war, b_war = validate_and_clean_data_enhanced(a_war, b_war)\n",
    "\n",
    "    print(f\"Successfully matched {len(a_warp)} pitchers with enhanced park factors\")\n",
    "    print(f\"2-way player fix applied to {len(two_way_players)} TRUE 2-way players\")\n",
    "    print(f\"Enhanced park factors applied to all players\")\n",
    "    print(f\"Index-based mapping FIXES duplicate name issues\")\n",
    "    print(f\"Enhanced baserunning with run expectancy REPLACES simple counting\")\n",
    "    print(f\"Neural network-safe data cleaning applied\")\n",
    "    print(f\"FIXED: Park factors loaded once instead of {len(hitter_pred_data) + len(pitcher_pred_data)} times\")\n",
    "    print(f\"NEW: Season information captured for {len(hitter_seasons_warp)} hitter + {len(pitcher_seasons_warp)} pitcher observations\")\n",
    "    print(f\"üöÄ READY FOR COMPREHENSIVE FANGRAPHS-ENHANCED MODELING!\")\n",
    "    \n",
    "    return (x_warp, y_warp, x_war, y_war, a_warp, b_warp, a_war, b_war,\n",
    "            hitter_names_warp, hitter_names_war, pitcher_names_warp, pitcher_names_war,\n",
    "            hitter_seasons_warp, hitter_seasons_war, pitcher_seasons_warp, pitcher_seasons_war)\n",
    "\n",
    "def prepare_train_test_splits():\n",
    "    \"\"\"\n",
    "    Prepare train/test splits using the enhanced data preparation WITH season information\n",
    "    \"\"\"\n",
    "    (x_warp, y_warp, x_war, y_war, a_warp, b_warp, a_war, b_war,\n",
    "     hitter_names_warp, hitter_names_war, pitcher_names_warp, pitcher_names_war,\n",
    "     hitter_seasons_warp, hitter_seasons_war, pitcher_seasons_warp, pitcher_seasons_war) = data_preparation()\n",
    "    \n",
    "    # Include season data in train/test splits\n",
    "    x_warp_train, x_warp_test, y_warp_train, y_warp_test, h_names_warp_train, h_names_warp_test, h_seasons_warp_train, h_seasons_warp_test = train_test_split(\n",
    "        x_warp, y_warp, hitter_names_warp, hitter_seasons_warp, test_size=0.25, train_size=0.75, random_state=1\n",
    "    )\n",
    "    x_war_train, x_war_test, y_war_train, y_war_test, h_names_war_train, h_names_war_test, h_seasons_war_train, h_seasons_war_test = train_test_split(\n",
    "        x_war, y_war, hitter_names_war, hitter_seasons_war, test_size=0.25, train_size=0.75, random_state=1\n",
    "    )\n",
    "    a_warp_train, a_warp_test, b_warp_train, b_warp_test, p_names_warp_train, p_names_warp_test, p_seasons_warp_train, p_seasons_warp_test = train_test_split(\n",
    "        a_warp, b_warp, pitcher_names_warp, pitcher_seasons_warp, test_size=0.25, train_size=0.75, random_state=1\n",
    "    )\n",
    "    \n",
    "    if len(a_war) > 0:\n",
    "        a_war_train, a_war_test, b_war_train, b_war_test, p_names_war_train, p_names_war_test, p_seasons_war_train, p_seasons_war_test = train_test_split(\n",
    "            a_war, b_war, pitcher_names_war, pitcher_seasons_war, test_size=0.25, train_size=0.75, random_state=1\n",
    "        )\n",
    "    else:\n",
    "        a_war_train, a_war_test, b_war_train, b_war_test = a_warp_train, a_warp_test, b_warp_train, b_warp_test\n",
    "        p_names_war_train, p_names_war_test = p_names_warp_train, p_names_warp_test\n",
    "        p_seasons_war_train, p_seasons_war_test = p_seasons_warp_train, p_seasons_warp_test\n",
    "\n",
    "    return (x_warp_train, x_warp_test, y_warp_train, y_warp_test,\n",
    "            x_war_train, x_war_test, y_war_train, y_war_test,\n",
    "            a_warp_train, a_warp_test, b_warp_train, b_warp_test,\n",
    "            a_war_train, a_war_test, b_war_train, b_war_test,\n",
    "            h_names_warp_test, h_names_war_test, p_names_warp_test, p_names_war_test,\n",
    "            h_seasons_warp_test, h_seasons_war_test, p_seasons_warp_test, p_seasons_war_test)\n",
    "\n",
    "print(\"‚úÖ Enhanced data preparation and train/test split functions loaded with COMPREHENSIVE FANGRAPHS INTEGRATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348cb460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_quadrant_analysis_px_toggle(model_results, season_col=\"Season\", model_names=None, show_hitters=True, show_pitchers=True):\n",
    "    \"\"\"\n",
    "    Enhanced quadrant analysis using Plotly Express facets with year-over-year animation.\n",
    "    Dual accuracy zone visualization (orange cross + green intersection) with clickable legend toggles.\n",
    "    ENHANCED: Comprehensive accuracy analysis with error percentage calculations\n",
    "    FIXED: Data display issues, chronological year sorting, improved legend positioning\n",
    "    \"\"\"\n",
    "    if model_names is None:\n",
    "        model_names = select_best_models_by_category(model_results)\n",
    "        print(f\"üéØ Auto-selected models: {[m.upper() for m in model_names]}\")\n",
    "\n",
    "    # FIXED: More robust data collection with debugging\n",
    "    data = []\n",
    "    data_found = False\n",
    "    \n",
    "    print(\"üîç Collecting data from model results...\")\n",
    "    for model in model_names:\n",
    "        for player_type in [\"hitter\", \"pitcher\"]:\n",
    "            for metric in [\"war\", \"warp\"]:\n",
    "                key = f\"{model}_{player_type}_{metric}\"\n",
    "                if key in model_results.results:\n",
    "                    res = model_results.results[key]\n",
    "                    if len(res[\"player_names\"]) > 0:\n",
    "                        data_found = True\n",
    "                        print(f\"   Found {len(res['player_names'])} entries for {key}\")\n",
    "                        \n",
    "                        for i, player in enumerate(res[\"player_names\"]):\n",
    "                            # FIXED: Better season handling with debugging\n",
    "                            if season_col in res and len(res[season_col]) > i and res[season_col][i] is not None:\n",
    "                                season_value = res[season_col][i]\n",
    "                                # Convert to int first for proper sorting, then back to string for consistency\n",
    "                                try:\n",
    "                                    season_int = int(season_value)\n",
    "                                    season_value = str(season_int)  # Normalized string format\n",
    "                                except (ValueError, TypeError):\n",
    "                                    season_value = str(season_value)\n",
    "                            else:\n",
    "                                season_value = \"2021\"  # Default\n",
    "\n",
    "                            data.append({\n",
    "                                \"Player\": player,\n",
    "                                \"Model\": model.title(),\n",
    "                                \"PlayerType\": player_type.title(),\n",
    "                                season_col: season_value,\n",
    "                                f\"Actual {metric.upper()}\": res[\"y_true\"][i],\n",
    "                                f\"Predicted {metric.upper()}\": res[\"y_pred\"][i]\n",
    "                            })\n",
    "                    else:\n",
    "                        print(f\"   No data for {key}\")\n",
    "                else:\n",
    "                    print(f\"   Key {key} not found in results\")\n",
    "\n",
    "    if not data_found or not data:\n",
    "        print(\"‚ùå No data available for quadrant analysis.\")\n",
    "        print(\"Available keys in model_results:\", list(model_results.results.keys())[:10])\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"‚úÖ Collected {len(df)} data points for analysis\")\n",
    "\n",
    "    # Enhanced delta and error calculations\n",
    "    df[\"WAR_Delta\"] = df[\"Actual WAR\"] - df[\"Predicted WAR\"]\n",
    "    df[\"WARP_Delta\"] = df[\"Actual WARP\"] - df[\"Predicted WARP\"]\n",
    "\n",
    "    # Error percentage calculations for 10% accuracy zone\n",
    "    df[\"WAR_Error_%\"] = abs(df[\"WAR_Delta\"]) / df[\"Actual WAR\"].replace(0, float(\"nan\")).abs() * 100\n",
    "    df[\"WARP_Error_%\"] = abs(df[\"WARP_Delta\"]) / df[\"Actual WARP\"].replace(0, float(\"nan\")).abs() * 100\n",
    "\n",
    "    # Multiple accuracy zone definitions\n",
    "    df[\"In_Accuracy_Zone\"] = (df[\"WAR_Error_%\"] <= 10) & (df[\"WARP_Error_%\"] <= 10)\n",
    "    df[\"WAR_Delta_1\"] = abs(df[\"WAR_Delta\"]) <= 1.0\n",
    "    df[\"WARP_Delta_1\"] = abs(df[\"WARP_Delta\"]) <= 1.0\n",
    "    df[\"Both_Delta_1\"] = df[\"WAR_Delta_1\"] & df[\"WARP_Delta_1\"]  # Green intersection\n",
    "    df[\"Either_Delta_1\"] = df[\"WAR_Delta_1\"] | df[\"WARP_Delta_1\"]  # Orange cross\n",
    "\n",
    "    df[\"AccuracyZone\"] = df[\"In_Accuracy_Zone\"].map({True: \"‚â§10% Error Both\", False: \"Outside Zone\"})\n",
    "    df[\"Delta1Zone\"] = df[\"Both_Delta_1\"].map({True: \"Both ‚â§1\", False: \"Outside ¬±1\"})\n",
    "\n",
    "    # FIXED: Proper chronological sorting for animation frames\n",
    "    unique_seasons = df[season_col].unique()\n",
    "    try:\n",
    "        # Convert to int for proper chronological sorting\n",
    "        sorted_seasons = sorted([int(s) for s in unique_seasons if s is not None])\n",
    "        # Convert back to strings for consistency\n",
    "        sorted_season_strings = [str(s) for s in sorted_seasons]\n",
    "        # Create categorical with proper order\n",
    "        df[season_col] = pd.Categorical(df[season_col], categories=sorted_season_strings, ordered=True)\n",
    "        print(f\"üìÖ Sorted seasons chronologically: {sorted_season_strings}\")\n",
    "    except (ValueError, TypeError):\n",
    "        # Fallback to string sorting\n",
    "        sorted_season_strings = sorted([str(s) for s in unique_seasons if s is not None])\n",
    "        df[season_col] = pd.Categorical(df[season_col], categories=sorted_season_strings, ordered=True)\n",
    "        print(f\"üìÖ Sorted seasons as strings: {sorted_season_strings}\")\n",
    "\n",
    "    min_val = min(df[\"WAR_Delta\"].min(), df[\"WARP_Delta\"].min())\n",
    "    max_val = max(df[\"WAR_Delta\"].max(), df[\"WARP_Delta\"].max())\n",
    "    buffer = (max_val - min_val) * 0.05\n",
    "\n",
    "    # Create the enhanced faceted figure\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x=\"WAR_Delta\",\n",
    "        y=\"WARP_Delta\",\n",
    "        color=\"PlayerType\",\n",
    "        symbol=\"AccuracyZone\",\n",
    "        hover_name=\"Player\",\n",
    "        facet_col=\"Model\",\n",
    "        facet_row=\"PlayerType\",\n",
    "        animation_frame=season_col,\n",
    "        animation_group=\"Player\",\n",
    "        title=\"Enhanced Quadrant Analysis: WAR vs WARP Deltas (Chronological Animation)\",\n",
    "        range_x=[min_val - buffer, max_val + buffer],\n",
    "        range_y=[min_val - buffer, max_val + buffer],\n",
    "        width=1200,\n",
    "        height=800,\n",
    "        template=\"seaborn\"\n",
    "    )\n",
    "\n",
    "    # Convert to go.Figure for advanced customization\n",
    "    fig = go.Figure(fig)\n",
    "\n",
    "    # Add quadrant reference lines\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", line_width=1)\n",
    "    fig.add_vline(x=0, line_dash=\"dash\", line_color=\"gray\", line_width=1)\n",
    "\n",
    "    # Add dual accuracy zone visualization\n",
    "    accuracy_shapes = []\n",
    "    \n",
    "    # Orange cross lines (¬±1 margins)\n",
    "    accuracy_shapes.extend([\n",
    "        dict(type=\"line\", x0=-1, y0=min_val-buffer, x1=-1, y1=max_val+buffer, \n",
    "             line=dict(color=\"orange\", width=2, dash=\"dot\")),\n",
    "        dict(type=\"line\", x0=1, y0=min_val-buffer, x1=1, y1=max_val+buffer, \n",
    "             line=dict(color=\"orange\", width=2, dash=\"dot\")),\n",
    "        dict(type=\"line\", x0=min_val-buffer, y0=-1, x1=max_val+buffer, y1=-1, \n",
    "             line=dict(color=\"orange\", width=2, dash=\"dot\")),\n",
    "        dict(type=\"line\", x0=min_val-buffer, y0=1, x1=max_val+buffer, y1=1, \n",
    "             line=dict(color=\"orange\", width=2, dash=\"dot\"))\n",
    "    ])\n",
    "\n",
    "    # Green intersection rectangle\n",
    "    accuracy_shapes.append(\n",
    "        dict(type=\"rect\", x0=-1, y0=-1, x1=1, y1=1,\n",
    "             line=dict(color=\"green\", width=2, dash=\"dash\"),\n",
    "             fillcolor=\"green\", opacity=0.1)\n",
    "    )\n",
    "\n",
    "    fig.update_layout(shapes=accuracy_shapes)\n",
    "\n",
    "    # FIXED: Improved legend positioning (above traces, not covering y-axis)\n",
    "    fig.update_layout(\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,  # Above the plot\n",
    "            xanchor=\"center\",\n",
    "            x=0.5,   # Centered horizontally\n",
    "            bgcolor=\"rgba(255,255,255,0.9)\",\n",
    "            bordercolor=\"gray\",\n",
    "            borderwidth=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # FIXED: Reposition animation controls to be usable\n",
    "    fig.update_layout(\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                type=\"buttons\",\n",
    "                direction=\"left\",\n",
    "                x=0.15,  # Moved right so not covered by legend\n",
    "                y=1.15,  # Above legend\n",
    "                showactive=True,\n",
    "                buttons=[\n",
    "                    dict(label=\"All Zones\", method=\"relayout\",\n",
    "                         args=[{\"shapes\": [{**s, \"visible\": True} for s in accuracy_shapes]}]),\n",
    "                    dict(label=\"Cross Only\", method=\"relayout\",\n",
    "                         args=[{\"shapes\": [{**s, \"visible\": True if \"line\" in s.get(\"type\", \"\") else False} \n",
    "                                          for s in accuracy_shapes]}]),\n",
    "                    dict(label=\"Intersection\", method=\"relayout\",\n",
    "                         args=[{\"shapes\": [{**s, \"visible\": True if s.get(\"type\") == \"rect\" else False} \n",
    "                                          for s in accuracy_shapes]}]),\n",
    "                    dict(label=\"No Zones\", method=\"relayout\",\n",
    "                         args=[{\"shapes\": [{**s, \"visible\": False} for s in accuracy_shapes]}])\n",
    "                ]\n",
    "            )\n",
    "        ],\n",
    "        # FIXED: Position animation controls to the right\n",
    "        sliders=[dict(\n",
    "            currentvalue={\"prefix\": \"Year: \"},\n",
    "            x=0.15,  # Moved right\n",
    "            len=0.7   # Adjusted length\n",
    "        )]\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    # Enhanced statistical summary with better formatting\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä INTERACTIVE QUADRANT ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for model in df[\"Model\"].unique():\n",
    "        mdf = df[df[\"Model\"] == model]\n",
    "        total = len(mdf)\n",
    "\n",
    "        acc_10pct = mdf[\"In_Accuracy_Zone\"].sum()\n",
    "        both_delta1 = mdf[\"Both_Delta_1\"].sum()\n",
    "        either_delta1 = mdf[\"Either_Delta_1\"].sum()\n",
    "\n",
    "        print(f\"\\nüîç {model.upper()} MODEL ({total} predictions):\")\n",
    "        print(f\"   üìà 10% Accuracy Zone (both WAR & WARP): {acc_10pct}/{total} ({acc_10pct/total*100:.1f}%)\")\n",
    "        print(f\"   üéØ Delta 1 Cross (either ‚â§1): {either_delta1}/{total} ({either_delta1/total*100:.1f}%)\")\n",
    "        print(f\"   ‚úÖ Delta 1 Intersection (both ‚â§1): {both_delta1}/{total} ({both_delta1/total*100:.1f}%)\")\n",
    "\n",
    "        # Sample accurate players\n",
    "        accurate_players = mdf[mdf[\"In_Accuracy_Zone\"]][\"Player\"].unique()\n",
    "        if len(accurate_players) > 0:\n",
    "            sample = \", \".join(list(accurate_players[:3]))\n",
    "            print(f\"   üåü Sample accurate: {sample}{'...' if len(accurate_players) > 3 else ''}\")\n",
    "\n",
    "    print(f\"\\nüí° INTERACTIVE FEATURES:\")\n",
    "    print(f\"   üñ±Ô∏è  Legend: Click PlayerType/AccuracyZone to show/hide\")\n",
    "    print(f\"   üé¨ Animation: Chronologically ordered year progression\")\n",
    "    print(f\"   üîò Accuracy Zones: Toggle orange cross vs green intersection\")\n",
    "    print(f\"   üéØ Hover: Detailed player performance information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56oizvcxhh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def plot_consolidated_model_comparison(model_results, model_names=None, show_residuals=True, show_metrics=True):\n",
    "    \"\"\"\n",
    "    Consolidated model comparison system that replaces individual print_metrics graphs.\n",
    "    Creates unified visualizations with selectable traces for easy comparison.\n",
    "\n",
    "    Args:\n",
    "        model_results: Your ModelResults object\n",
    "        model_names: List of models to compare (None = auto-select best)\n",
    "        show_residuals: Whether to include residual analysis plots\n",
    "        show_metrics: Whether to include scatter plot comparisons\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with analysis results for each model\n",
    "    \"\"\"\n",
    "    if model_names is None:\n",
    "        model_names = select_best_models_by_category(model_results)\n",
    "        print(f\"üéØ Auto-selected models for comparison: {[m.upper() for m in model_names]}\")\n",
    "\n",
    "    print(\"\\nüìä CONSOLIDATED MODEL COMPARISON SYSTEM\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"üîç Replacing individual graphs with unified selectable trace visualizations...\")\n",
    "\n",
    "    # Collect all data for consolidated visualizations\n",
    "    all_data = []\n",
    "    model_stats = {}\n",
    "\n",
    "    for model_name in model_names:\n",
    "        model_stats[model_name] = {}\n",
    "\n",
    "        for player_type in ['hitter', 'pitcher']:\n",
    "            for metric in ['war', 'warp']:\n",
    "                key = f\"{model_name}_{player_type}_{metric}\"\n",
    "                if key in model_results.results:\n",
    "                    data = model_results.results[key]\n",
    "\n",
    "                    if len(data['y_true']) > 0:\n",
    "                        y_true = np.array(data['y_true'])\n",
    "                        y_pred = np.array(data['y_pred'])\n",
    "                        residuals = y_true - y_pred\n",
    "\n",
    "                        # Calculate comprehensive statistics\n",
    "                        rmse = np.sqrt(np.mean(residuals**2))\n",
    "                        mae = np.mean(np.abs(residuals))\n",
    "                        r2 = 1 - (np.sum(residuals**2) / np.sum((y_true - np.mean(y_true))**2))\n",
    "\n",
    "                        # Store statistics\n",
    "                        model_stats[model_name][f\"{player_type}_{metric}\"] = {\n",
    "                            'rmse': rmse,\n",
    "                            'mae': mae,\n",
    "                            'r2': r2,\n",
    "                            'count': len(y_true)\n",
    "                        }\n",
    "\n",
    "                        # Add to plotting data\n",
    "                        for i in range(len(residuals)):\n",
    "                            all_data.append({\n",
    "                                'Model': model_name.title(),\n",
    "                                'PlayerType': player_type.title(),\n",
    "                                'Metric': metric.upper(),\n",
    "                                'Category': f\"{player_type.title()} {metric.upper()}\",\n",
    "                                'Actual': y_true[i],\n",
    "                                'Predicted': y_pred[i],\n",
    "                                'Residual': residuals[i],\n",
    "                                'Player': data['player_names'][i] if 'player_names' in data else f\"Player_{i}\"\n",
    "                            })\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"‚ùå No data available for consolidated comparison\")\n",
    "        return {}\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Utility: add group toggle buttons\n",
    "    def add_group_buttons(fig, group_labels):\n",
    "        n_traces = len(fig.data)\n",
    "        buttons = []\n",
    "\n",
    "        for g in group_labels:\n",
    "            buttons.append(\n",
    "                dict(\n",
    "                    label=f\"Toggle {g}\",\n",
    "                    method=\"restyle\",\n",
    "                    args=[\n",
    "                        {\"visible\": \"toggle\"},\n",
    "                        [i for i, tr in enumerate(fig.data) if tr.legendgroup == g]\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Show all\n",
    "        buttons.append(\n",
    "            dict(\n",
    "                label=\"Show All\",\n",
    "                method=\"restyle\",\n",
    "                args=[{\"visible\": True}, list(range(n_traces))]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            updatemenus=[dict(\n",
    "                type=\"buttons\",\n",
    "                direction=\"right\",\n",
    "                x=0.5, xanchor=\"center\",\n",
    "                y=1.15, yanchor=\"top\",\n",
    "                buttons=buttons\n",
    "            )]\n",
    "        )\n",
    "\n",
    "    # 1. CONSOLIDATED SCATTER PLOTS WITH SELECTABLE TRACES\n",
    "    if show_metrics:\n",
    "        print(\"\\nüìà Creating consolidated prediction accuracy plots...\")\n",
    "\n",
    "        fig_scatter = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=['Hitter WAR', 'Hitter WARP', 'Pitcher WAR', 'Pitcher WARP'],\n",
    "            vertical_spacing=0.1,\n",
    "            horizontal_spacing=0.1\n",
    "        )\n",
    "\n",
    "        colors = px.colors.qualitative.Set1\n",
    "\n",
    "        for i, category in enumerate(['Hitter WAR', 'Hitter WARP', 'Pitcher WAR', 'Pitcher WARP']):\n",
    "            cat_data = df[df['Category'] == category]\n",
    "\n",
    "            row = (i // 2) + 1\n",
    "            col = (i % 2) + 1\n",
    "\n",
    "            for j, model in enumerate(cat_data['Model'].unique()):\n",
    "                model_data = cat_data[cat_data['Model'] == model]\n",
    "\n",
    "                fig_scatter.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=model_data['Actual'],\n",
    "                        y=model_data['Predicted'],\n",
    "                        mode='markers',\n",
    "                        name=f\"{model} {category}\",\n",
    "                        legendgroup=model,\n",
    "                        marker=dict(color=colors[j % len(colors)], size=6, opacity=0.7),\n",
    "                        text=model_data['Player'],\n",
    "                        hovertemplate=\"<b>%{text}</b><br>\" +\n",
    "                                      \"Actual: %{x:.3f}<br>\" +\n",
    "                                      \"Predicted: %{y:.3f}<br>\" +\n",
    "                                      f\"Model: {model}<br>\" +\n",
    "                                      \"<extra></extra>\",\n",
    "                        showlegend=(i == 0)\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "\n",
    "                # Add perfect prediction line\n",
    "                if j == 0:  # Only add once per subplot\n",
    "                    min_val = min(model_data['Actual'].min(), model_data['Predicted'].min())\n",
    "                    max_val = max(model_data['Actual'].max(), model_data['Predicted'].max())\n",
    "\n",
    "                    fig_scatter.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=[min_val, max_val],\n",
    "                            y=[min_val, max_val],\n",
    "                            mode='lines',\n",
    "                            line=dict(dash='dash', color='red', width=2),\n",
    "                            name='Perfect Prediction',\n",
    "                            legendgroup='Perfect Prediction',\n",
    "                            showlegend=(i == 0)\n",
    "                        ),\n",
    "                        row=row, col=col\n",
    "                    )\n",
    "\n",
    "        fig_scatter.update_layout(\n",
    "            title=\"Consolidated Model Comparison: Prediction Accuracy (Click Legend or Use Buttons to Toggle)\",\n",
    "            height=800,\n",
    "            width=1200,\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"center\", x=0.5)\n",
    "        )\n",
    "\n",
    "        add_group_buttons(fig_scatter, df['Model'].unique())\n",
    "        fig_scatter.show()\n",
    "\n",
    "    # 2. CONSOLIDATED RESIDUAL ANALYSIS\n",
    "    if show_residuals:\n",
    "        print(\"\\nüîç Creating consolidated residual analysis...\")\n",
    "\n",
    "        fig_residuals = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=['Residuals vs Fitted', 'Residual Distributions', 'Q-Q Plot', 'Model Performance'],\n",
    "            specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "                   [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "        )\n",
    "\n",
    "        # Residuals vs Fitted\n",
    "        for j, model in enumerate(df['Model'].unique()):\n",
    "            model_data = df[df['Model'] == model]\n",
    "\n",
    "            fig_residuals.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=model_data['Predicted'],\n",
    "                    y=model_data['Residual'],\n",
    "                    mode='markers',\n",
    "                    name=f\"{model} Residuals\",\n",
    "                    legendgroup=model,\n",
    "                    marker=dict(color=colors[j % len(colors)], size=4, opacity=0.6),\n",
    "                    showlegend=True\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "\n",
    "        # Add horizontal line at y=0\n",
    "        fig_residuals.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", row=1, col=1)\n",
    "\n",
    "        # Residual Distributions\n",
    "        for j, model in enumerate(df['Model'].unique()):\n",
    "            model_data = df[df['Model'] == model]\n",
    "\n",
    "            fig_residuals.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=model_data['Residual'],\n",
    "                    name=f\"{model} Distribution\",\n",
    "                    legendgroup=model,\n",
    "                    opacity=0.7,\n",
    "                    nbinsx=30,\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "\n",
    "        # Q-Q Plot (simplified - one model for clarity)\n",
    "        if len(df['Model'].unique()) > 0:\n",
    "            best_model = df['Model'].unique()[0]\n",
    "            best_data = df[df['Model'] == best_model]\n",
    "            residuals = best_data['Residual'].values\n",
    "\n",
    "            sorted_residuals = np.sort(residuals)\n",
    "            n = len(sorted_residuals)\n",
    "            theoretical_quantiles = stats.norm.ppf(np.linspace(0.01, 0.99, n))\n",
    "\n",
    "            fig_residuals.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=theoretical_quantiles,\n",
    "                    y=sorted_residuals,\n",
    "                    mode='markers',\n",
    "                    name=f\"{best_model} Q-Q\",\n",
    "                    legendgroup=best_model,\n",
    "                    marker=dict(size=4),\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "\n",
    "            # Theoretical line\n",
    "            slope = np.std(residuals)\n",
    "            intercept = np.mean(residuals)\n",
    "            line_min, line_max = min(theoretical_quantiles), max(theoretical_quantiles)\n",
    "\n",
    "            fig_residuals.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=[line_min, line_max],\n",
    "                    y=[intercept + slope * line_min, intercept + slope * line_max],\n",
    "                    mode='lines',\n",
    "                    line=dict(color='red', dash='dash'),\n",
    "                    name='Normal Line',\n",
    "                    legendgroup='Normal Line',\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "\n",
    "        # Model Performance Comparison\n",
    "        models = list(model_stats.keys())\n",
    "        metrics = ['R¬≤', 'RMSE', 'MAE']\n",
    "\n",
    "        for metric_name in metrics:\n",
    "            metric_values = []\n",
    "            for model in models:\n",
    "                # Average across all model variants\n",
    "                values = []\n",
    "                for key, model_stat_data in model_stats[model].items():\n",
    "                    if metric_name == 'R¬≤':\n",
    "                        values.append(model_stat_data['r2'])\n",
    "                    elif metric_name == 'RMSE':\n",
    "                        values.append(model_stat_data['rmse'])\n",
    "                    elif metric_name == 'MAE':\n",
    "                        values.append(model_stat_data['mae'])\n",
    "\n",
    "                metric_values.append(np.mean(values) if values else 0)\n",
    "\n",
    "            fig_residuals.add_trace(\n",
    "                go.Bar(\n",
    "                    x=models,\n",
    "                    y=metric_values,\n",
    "                    name=metric_name,\n",
    "                    legendgroup=metric_name,\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=2\n",
    "            )\n",
    "\n",
    "        fig_residuals.update_layout(\n",
    "            title=\"Consolidated Residual Analysis (Click Legend or Use Buttons to Toggle Models)\",\n",
    "            height=800,\n",
    "            width=1200,\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"center\", x=0.5)\n",
    "        )\n",
    "\n",
    "        add_group_buttons(fig_residuals, df['Model'].unique())\n",
    "        fig_residuals.show()\n",
    "\n",
    "    # 3. COMPREHENSIVE STATISTICAL SUMMARY\n",
    "    print(\"\\nüìã CONSOLIDATED MODEL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    for model_name in model_names:\n",
    "        if model_name in model_stats:\n",
    "            print(f\"\\nü§ñ {model_name.upper()} MODEL:\")\n",
    "\n",
    "            total_predictions = sum(model_stat_data['count'] for model_stat_data in model_stats[model_name].values())\n",
    "            avg_r2 = np.mean([model_stat_data['r2'] for model_stat_data in model_stats[model_name].values()])\n",
    "            avg_rmse = np.mean([model_stat_data['rmse'] for model_stat_data in model_stats[model_name].values()])\n",
    "            avg_mae = np.mean([model_stat_data['mae'] for model_stat_data in model_stats[model_name].values()])\n",
    "\n",
    "            print(f\"   üìä Overall Performance:\")\n",
    "            print(f\"      ‚Ä¢ Total Predictions: {total_predictions}\")\n",
    "            print(f\"      ‚Ä¢ Average R¬≤: {avg_r2:.4f}\")\n",
    "            print(f\"      ‚Ä¢ Average RMSE: {avg_rmse:.4f}\")\n",
    "            print(f\"      ‚Ä¢ Average MAE: {avg_mae:.4f}\")\n",
    "\n",
    "            print(f\"   üìà By Category:\")\n",
    "            for key, model_stat_data in model_stats[model_name].items():\n",
    "                category = key.replace('_', ' ').title()\n",
    "                print(f\"      ‚Ä¢ {category}: R¬≤={model_stat_data['r2']:.4f}, RMSE={model_stat_data['rmse']:.4f}, Count={model_stat_data['count']}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ CONSOLIDATED COMPARISON COMPLETE\")\n",
    "    print(f\"   üìà Unified scatter plots: All models on same plots with toggleable traces\")\n",
    "    print(f\"   üîç Integrated residual analysis: Comprehensive diagnostic plots\")\n",
    "    print(f\"   üìä Statistical summary: Complete performance metrics\")\n",
    "    print(f\"   üñ±Ô∏è  Interactive legends: Click to show/hide individual models, use buttons for group control\")\n",
    "\n",
    "    return model_stats\n",
    "\n",
    "\n",
    "def plot_comprehensive_residual_analysis(model_results, model_names=None, player_type=\"both\", metric=\"both\"):\n",
    "    \"\"\"\n",
    "    Comprehensive residual plot comparison system for ML model diagnostics.\n",
    "\n",
    "    This function creates multiple residual visualizations to diagnose model performance:\n",
    "    1. Residuals vs Fitted Values (heteroscedasticity detection)\n",
    "    2. Q-Q plots (normality assessment)\n",
    "    3. Residual distribution histograms\n",
    "    4. Scale-Location plots (variance homogeneity)\n",
    "    5. Model comparison summary statistics\n",
    "\n",
    "    Args:\n",
    "        model_results: Your ModelResults object\n",
    "        model_names: List of models to compare (None = auto-select best)\n",
    "        player_type: 'hitter', 'pitcher', or 'both'\n",
    "        metric: 'war', 'warp', or 'both'\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with residual analysis results for each model\n",
    "    \"\"\"\n",
    "    # Use the new consolidated system\n",
    "    return plot_consolidated_model_comparison(model_results, model_names, show_residuals=True, show_metrics=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348cb460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_quadrant_analysis_px_toggle(model_results, season_col=\"Season\", model_names=None, show_hitters=True, show_pitchers=True):\n",
    "    \"\"\"\n",
    "    Enhanced quadrant analysis using Plotly Express facets with year-over-year animation.\n",
    "    Dual accuracy zone visualization (orange cross + green intersection) with clickable legend toggles.\n",
    "    ENHANCED: Comprehensive accuracy analysis with error percentage calculations\n",
    "    FIXED: Handles missing season data gracefully\n",
    "    \"\"\"\n",
    "    if model_names is None:\n",
    "        model_names = select_best_models_by_category(model_results)\n",
    "        print(f\"üéØ Auto-selected models: {[m.upper() for m in model_names]}\")\n",
    "\n",
    "    # Collect long-form data (always include both player types for interactive toggling)\n",
    "    data = []\n",
    "    for model in model_names:\n",
    "        for player_type in [\"hitter\", \"pitcher\"]:\n",
    "            for metric in [\"war\", \"warp\"]:\n",
    "                key = f\"{model}_{player_type}_{metric}\"\n",
    "                if key in model_results.results:\n",
    "                    res = model_results.results[key]\n",
    "                    for i, player in enumerate(res[\"player_names\"]):\n",
    "                        # FIXED: Handle missing season data gracefully\n",
    "                        if season_col in res and len(res[season_col]) > i:\n",
    "                            season_value = res[season_col][i]\n",
    "                        else:\n",
    "                            season_value = \"2021\"  # Default season placeholder\n",
    "\n",
    "                        data.append({\n",
    "                            \"Player\": player,\n",
    "                            \"Model\": model.title(),\n",
    "                            \"PlayerType\": player_type.title(),\n",
    "                            season_col: season_value,\n",
    "                            f\"Actual {metric.upper()}\": res[\"y_true\"][i],\n",
    "                            f\"Predicted {metric.upper()}\": res[\"y_pred\"][i]\n",
    "                        })\n",
    "\n",
    "    if not data:\n",
    "        print(\"No data available for quadrant analysis.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Enhanced delta and error calculations\n",
    "    df[\"WAR_Delta\"] = df[\"Actual WAR\"] - df[\"Predicted WAR\"]\n",
    "    df[\"WARP_Delta\"] = df[\"Actual WARP\"] - df[\"Predicted WARP\"]\n",
    "\n",
    "    # Error percentage calculations for 10% accuracy zone\n",
    "    df[\"WAR_Error_%\"] = abs(df[\"WAR_Delta\"]) / df[\"Actual WAR\"].replace(0, float(\"nan\")).abs() * 100\n",
    "    df[\"WARP_Error_%\"] = abs(df[\"WARP_Delta\"]) / df[\"Actual WARP\"].replace(0, float(\"nan\")).abs() * 100\n",
    "\n",
    "    # Multiple accuracy zone definitions\n",
    "    df[\"In_Accuracy_Zone\"] = (df[\"WAR_Error_%\"] <= 10) & (df[\"WARP_Error_%\"] <= 10)  # 10% both\n",
    "    df[\"WAR_Delta_1\"] = abs(df[\"WAR_Delta\"]) <= 1.0  # Delta 1 margins\n",
    "    df[\"WARP_Delta_1\"] = abs(df[\"WARP_Delta\"]) <= 1.0\n",
    "    df[\"Both_Delta_1\"] = df[\"WAR_Delta_1\"] & df[\"WARP_Delta_1\"]  # Green intersection\n",
    "    df[\"Either_Delta_1\"] = df[\"WAR_Delta_1\"] | df[\"WARP_Delta_1\"]  # Orange cross\n",
    "\n",
    "    df[\"AccuracyZone\"] = df[\"In_Accuracy_Zone\"].map({True: \"‚â§10% Error Both\", False: \"Outside Zone\"})\n",
    "    df[\"Delta1Zone\"] = df[\"Both_Delta_1\"].map({True: \"Both ‚â§1\", False: \"Outside ¬±1\"})\n",
    "\n",
    "    min_val = min(df[\"WAR_Delta\"].min(), df[\"WARP_Delta\"].min())\n",
    "    max_val = max(df[\"WAR_Delta\"].max(), df[\"WARP_Delta\"].max())\n",
    "    buffer = (max_val - min_val) * 0.05\n",
    "\n",
    "    # Create the base PX figure\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x=\"WAR_Delta\",\n",
    "        y=\"WARP_Delta\",\n",
    "        color=\"PlayerType\",\n",
    "        symbol=\"AccuracyZone\",\n",
    "        hover_name=\"Player\",\n",
    "        facet_col=\"Model\",\n",
    "        facet_row=\"PlayerType\",\n",
    "        animation_frame=season_col,\n",
    "        animation_group=\"Player\",\n",
    "        title=\"Enhanced Quadrant Analysis: WAR vs WARP Deltas (Click Legend to Toggle)\",\n",
    "        range_x=[min_val - buffer, max_val + buffer],\n",
    "        range_y=[min_val - buffer, max_val + buffer],\n",
    "        width=1200,\n",
    "        height=800,\n",
    "        template=\"seaborn\"\n",
    "    )\n",
    "\n",
    "    # Convert to go.Figure to add shapes and customize legend\n",
    "    fig = go.Figure(fig)\n",
    "\n",
    "    # Add quadrant reference lines\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\")\n",
    "    fig.add_vline(x=0, line_dash=\"dash\", line_color=\"gray\")\n",
    "\n",
    "    # Add DUAL accuracy zone visualization (orange cross + green intersection)\n",
    "    cross_shapes = []  # Orange cross lines (¬±1 margins)\n",
    "    intersection_shapes = []  # Green intersection rectangle\n",
    "\n",
    "    for row in df[\"PlayerType\"].unique():\n",
    "        for col in df[\"Model\"].unique():\n",
    "            # Orange cross lines (WAR‚â§1 OR WARP‚â§1)\n",
    "            cross_shapes.extend([\n",
    "                dict(type=\"line\", x0=-1, y0=-4, x1=-1, y1=4, line=dict(color=\"orange\", width=3, dash=\"dot\")),  # Vertical left\n",
    "                dict(type=\"line\", x0=1, y0=-4, x1=1, y1=4, line=dict(color=\"orange\", width=3, dash=\"dot\")),    # Vertical right\n",
    "                dict(type=\"line\", x0=-4, y0=-1, x1=4, y1=-1, line=dict(color=\"orange\", width=3, dash=\"dot\")),  # Horizontal bottom\n",
    "                dict(type=\"line\", x0=-4, y0=1, x1=4, y1=1, line=dict(color=\"orange\", width=3, dash=\"dot\"))    # Horizontal top\n",
    "            ])\n",
    "\n",
    "            # Green intersection rectangle (WAR‚â§1 AND WARP‚â§1)\n",
    "            intersection_shapes.append(\n",
    "                dict(\n",
    "                    type=\"rect\",\n",
    "                    x0=-1, y0=-1, x1=1, y1=1,\n",
    "                    line=dict(color=\"green\", width=2, dash=\"dash\"),\n",
    "                    fillcolor=\"green\",\n",
    "                    opacity=0.1,\n",
    "                    visible=True\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Combine all accuracy zone shapes\n",
    "    all_accuracy_shapes = cross_shapes + intersection_shapes\n",
    "    fig.update_layout(shapes=all_accuracy_shapes)\n",
    "\n",
    "    # Configure interactive legend (horizontal, inside plot, top-left)\n",
    "    fig.update_layout(\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"top\",\n",
    "            y=0.98,\n",
    "            xanchor=\"left\", \n",
    "            x=0.01,\n",
    "            bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "            bordercolor=\"gray\",\n",
    "            borderwidth=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add accuracy zone toggle buttons (keep minimal for zones only)\n",
    "    fig.update_layout(\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                type=\"buttons\",\n",
    "                direction=\"left\",\n",
    "                x=0.02,\n",
    "                y=0.02,\n",
    "                showactive=True,\n",
    "                buttons=[\n",
    "                    dict(\n",
    "                        label=\"All Zones\",\n",
    "                        method=\"relayout\",\n",
    "                        args=[{\"shapes\": [{**s, \"visible\": True} for s in all_accuracy_shapes]}]\n",
    "                    ),\n",
    "                    dict(\n",
    "                        label=\"Cross Only\",\n",
    "                        method=\"relayout\",\n",
    "                        args=[{\"shapes\": [{**s, \"visible\": True if s in cross_shapes else False} for s in all_accuracy_shapes]}]\n",
    "                    ),\n",
    "                    dict(\n",
    "                        label=\"Intersection\",\n",
    "                        method=\"relayout\",\n",
    "                        args=[{\"shapes\": [{**s, \"visible\": True if s in intersection_shapes else False} for s in all_accuracy_shapes]}]\n",
    "                    ),\n",
    "                    dict(\n",
    "                        label=\"No Zones\",\n",
    "                        method=\"relayout\",\n",
    "                        args=[{\"shapes\": [{**s, \"visible\": False} for s in all_accuracy_shapes]}]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        ],\n",
    "        annotations=[\n",
    "            dict(text=\"Accuracy Zones:\", x=0.02, y=0.06, xref=\"paper\", yref=\"paper\", align=\"left\", showarrow=False)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    # Enhanced statistical summary\n",
    "    print(\"=== INTERACTIVE QUADRANT ANALYSIS SUMMARY ===\")\n",
    "    for model in df[\"Model\"].unique():\n",
    "        mdf = df[df[\"Model\"] == model]\n",
    "        total = len(mdf)\n",
    "\n",
    "        acc_10pct = mdf[\"In_Accuracy_Zone\"].sum()\n",
    "        both_delta1 = mdf[\"Both_Delta_1\"].sum()\n",
    "        either_delta1 = mdf[\"Either_Delta_1\"].sum()\n",
    "\n",
    "        print(f\"\\n{model} ({total} entries):\")\n",
    "        print(f\"  10% Accuracy Zone (both): {acc_10pct} ({acc_10pct/total*100:.1f}%)\")\n",
    "        print(f\"  Delta 1 Cross (either): {either_delta1} ({either_delta1/total*100:.1f}%)\")\n",
    "        print(f\"  Delta 1 Intersection (both): {both_delta1} ({both_delta1/total*100:.1f}%)\")\n",
    "\n",
    "    print(f\"\\nüí° INTERACTIVE CONTROLS:\")\n",
    "    print(f\"   ‚Ä¢ Legend: Click PlayerType/AccuracyZone items to show/hide traces\")\n",
    "    print(f\"   ‚Ä¢ Accuracy Zone buttons: Toggle visualization overlays\")\n",
    "    print(f\"   ‚Ä¢ Animation: Play through seasons to see temporal patterns\")\n",
    "    print(f\"   ‚Ä¢ Hover: Detailed player information with error percentages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56oizvcxhh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== EXECUTE THE COMPLETE PIPELINE WITH ENHANCED MODULARIZED FUNCTIONS =====\n",
    "try:\n",
    "    \n",
    "    # Prepare data\n",
    "    print(\"\\nPreparing data with fuzzy matching and caching...\")\n",
    "    data_splits = prepare_train_test_splits()\n",
    "    print(\"Data preparation complete!\")\n",
    "    \n",
    "    # Run all models using modularized functions\n",
    "    print(\"\\n1. Running Basic Regression Models (including NEW Ridge)...\")\n",
    "    run_basic_regressions(data_splits, model_results, print_metrics, plot_results)\n",
    "    \n",
    "    print(\"\\n2. Running Advanced Models...\")\n",
    "    run_advanced_models(data_splits, model_results, print_metrics, plot_results)\n",
    "    \n",
    "    # print(\"\\n3. Running NEW Ensemble Models (AdaBoost)...\")\n",
    "    # run_ensemble_models(data_splits, model_results, print_metrics, plot_results)\n",
    "    \n",
    "    print(\"\\n4. Running NEW Non-linear Models (SVR + Gaussian Process)...\")\n",
    "    run_nonlinear_models(data_splits, model_results, print_metrics, plot_results)\n",
    "\n",
    "    print(\"\\n5. Running Neural Network with AdamW optimizer...\")\n",
    "    run_neural_network(data_splits, model_results, print_metrics, plot_results, plot_training_history)\n",
    "    \n",
    "    # Apply PROPER WAR adjustments with real position data\n",
    "    print(\"\\n6. Applying PROPER WAR Adjustments with Real Position Data...\")\n",
    "    adjusted_model_results = apply_proper_war_adjustments(model_results)\n",
    "\n",
    "    # Generate ENHANCED quadrant analysis with all missing features integrated\n",
    "    print(\"\\n7. Generating ENHANCED Analysis (comprehensive statistics + dual accuracy zones)...\")\n",
    "    \n",
    "    # Enhanced faceted quadrant analysis with dual zones and player type toggles\n",
    "    print(\"\\nüìä ENHANCED QUADRANT ANALYSIS (Faceted with Dual Accuracy Zones):\")\n",
    "    plot_quadrant_analysis_px_toggle(\n",
    "        adjusted_model_results, \n",
    "        show_hitters=True, \n",
    "        show_pitchers=True  # Use False to reduce data density if needed\n",
    "    )\n",
    "    \n",
    "    # Enhanced animated analysis with comprehensive statistics\n",
    "    print(\"\\nüé¨ ENHANCED ANIMATED ANALYSIS (Comprehensive Statistics + Dual Zones):\")\n",
    "    plot_war_warp_animated(\n",
    "        adjusted_model_results,\n",
    "        show_hitters=True,\n",
    "        show_pitchers=True  # Use False to reduce data density if needed  \n",
    "    )\n",
    "    \n",
    "    print(\"\\nüéâ COMPLETE ENHANCED MODEL SUITE TESTING FINISHED!\")\n",
    "    print(\"   Total algorithms tested: 10\")\n",
    "    print(\"   ‚Ä¢ Linear methods: Ridge, ElasticNet\")\n",
    "    print(\"   ‚Ä¢ Tree/Ensemble: KNN, Random Forest, XGBoost\") \n",
    "    print(\"   ‚Ä¢ Non-linear: SVR\")\n",
    "    print(\"   ‚Ä¢ Neural: Keras with AdamW\")\n",
    "    print(\"\\n‚ú® ENHANCED ANALYSIS FEATURES:\")\n",
    "    print(\"   ‚Ä¢ Dual accuracy zones: Orange cross (¬±1 margins) + Green intersection\")\n",
    "    print(\"   ‚Ä¢ Comprehensive statistics: All metrics from original quadrant analysis\")\n",
    "    print(r\"   ‚Ä¢ Error percentage calculations: 10% accuracy zone analysis\")\n",
    "    print(\"   ‚Ä¢ Toggleable player types: Reduce data density when needed\")\n",
    "    print(\"   ‚Ä¢ Sample player examples: Shows which players fall in accuracy zones\")\n",
    "    print(\"   ‚Ä¢ Year-over-year consistency: Temporal accuracy patterns\")\n",
    "    print(\"   ‚Ä¢ Faceted visualization: Player type √ó Model matrix view\")\n",
    "    print(\"   ‚Ä¢ Animation-ready: Seamless temporal visualization\")\n",
    "    \n",
    "    print(\"\\nüí° USAGE TIPS:\")\n",
    "    print(\"   ‚Ä¢ Use show_hitters=False to focus on pitchers only\")\n",
    "    print(\"   ‚Ä¢ Use show_pitchers=False to focus on hitters only\") \n",
    "    print(\"   ‚Ä¢ Toggle accuracy zone buttons in faceted plot for different views\")\n",
    "    print(\"   ‚Ä¢ Animation shows prediction evolution over seasons\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
