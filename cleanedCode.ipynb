{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "737bba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from cleanedDataParser import *\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p0m01cl7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def print_metrics(name, y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(f\"{name} - R2: {r2:.4f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "\n",
    "def plot_results(title, y_true, y_pred):\n",
    "    df = pd.DataFrame({'Predicted': y_pred, 'Actual': y_true})\n",
    "    fig = px.scatter(df, x='Predicted', y='Actual', title=title)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_training_history(history, title):\n",
    "    \"\"\"Plot training and validation loss curves\"\"\"\n",
    "    fig = make_subplots(rows=1, cols=2, \n",
    "                        subplot_titles=('Loss', 'Mean Absolute Error'))\n",
    "    \n",
    "    # Loss plot\n",
    "    fig.add_trace(go.Scatter(y=history.history['loss'], name='Train Loss'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(y=history.history['val_loss'], name='Val Loss'), row=1, col=1)\n",
    "    \n",
    "    # MAE plot\n",
    "    fig.add_trace(go.Scatter(y=history.history['mae'], name='Train MAE'), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(y=history.history['val_mae'], name='Val MAE'), row=1, col=2)\n",
    "    \n",
    "    fig.update_layout(title=f\"Training History - {title}\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def create_keras_model(input_dim, name=\"model\"):\n",
    "    \"\"\"Create an optimized Keras neural network\"\"\"\n",
    "    model = tf.keras.Sequential([ # pyright: ignore[reportAttributeAccessIssue]\n",
    "        tf.keras.layers.Dense(32, activation='relu', input_dim=input_dim, name=f'{name}_input'),  # Reduced from 64 # pyright: ignore[reportAttributeAccessIssue]\n",
    "        tf.keras.layers.Dropout(0.3, name=f'{name}_dropout1'), # pyright: ignore[reportAttributeAccessIssue]\n",
    "        tf.keras.layers.Dense(16, activation='relu', name=f'{name}_hidden1'), # pyright: ignore[reportAttributeAccessIssue]\n",
    "        tf.keras.layers.Dropout(0.2, name=f'{name}_dropout2'), # pyright: ignore[reportAttributeAccessIssue]\n",
    "        tf.keras.layers.Dense(1, activation='linear', name=f'{name}_output') # pyright: ignore[reportAttributeAccessIssue]\n",
    "    ], name=name)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lwloe0d3moq",
   "metadata": {},
   "outputs": [],
   "source": "# Data Preparation with Baserunning and Defense\ndef data_preparation():\n    print(\"Loading and preparing data...\")\n\n    # Load data from parser - now properly aggregated to season level\n    hitter_data = clean_sorted_hitter()  # Now returns aggregated season data\n    hitter_pred_data = clean_warp_hitter()  # Already season level\n    pitcher_data = clean_sorted_pitcher()  # Now returns aggregated season data\n    pitcher_pred_data = clean_warp_pitcher()  # Already season level\n    war_values = clean_war()  # Already season level\n    baserunning_values = clean_sorted_baserunning()  # Game level → player totals\n    defensive_values = clean_defensive_players()  # Game level → player totals\n\n    print(f\"Loaded data - Hitters: {len(hitter_data)}, WARP hitters: {len(hitter_pred_data)}, WAR: {len(war_values)}\")\n    print(f\"Baserunning values: {len(baserunning_values)}, Defensive values: {len(defensive_values)}\")\n\n    # Create name mappings using the new fuzzy matching functions\n    print(\"Creating name mappings...\")\n    warp_to_hitter_map = create_name_mapping(\n        hitter_pred_data['Name'].tolist(),\n        hitter_data['Hitters'].tolist()\n    )\n    warp_to_war_map = create_name_mapping(\n        hitter_pred_data['Name'].tolist(),\n        war_values['Name'].tolist()\n    )\n\n    # No need for additional aggregation - data is already season-level\n    hitter_stats = hitter_data  # Already aggregated in clean_sorted_hitter()\n\n    # Hitter features & targets (now with baserunning and defense)\n    x_warp, y_warp, x_war, y_war = [], [], [], []\n    hitter_names_warp, hitter_names_war = [], []\n\n    for index, row in hitter_pred_data.iterrows():\n        warp_name = row['Name']\n        \n        # Use the new fuzzy matching\n        hitter_match = warp_to_hitter_map.get(warp_name)\n        if hitter_match:\n            # Get season stats for this player\n            player_stats = hitter_stats[hitter_stats['Hitters'] == hitter_match]\n            if not player_stats.empty:\n                # Original 5 features\n                stats = player_stats[['K','BB','AVG','OBP','SLG']].values.flatten().tolist()\n                \n                # Add baserunning value (default 0 if not found)\n                baserunning_val = baserunning_values.get(hitter_match, 0)\n                stats.append(baserunning_val)\n                \n                # Add defensive value (default 0 if not found)  \n                defensive_val = defensive_values.get(hitter_match, 0)\n                stats.append(defensive_val)\n                \n                x_warp.append(stats)\n                y_warp.append(row['WARP'])\n                hitter_names_warp.append(warp_name)\n                \n                # Try to get WAR value using fuzzy matching\n                war_match = warp_to_war_map.get(warp_name)\n                if war_match:\n                    war_row = war_values[war_values['Name'] == war_match]\n                    if not war_row.empty:\n                        x_war.append(stats)\n                        y_war.append(war_row['Total WAR'].iloc[0])\n                        hitter_names_war.append(warp_name)\n                    else:\n                        x_war.append(stats)\n                        y_war.append(row['WARP'])  # fallback to WARP\n                        hitter_names_war.append(warp_name)\n                else:\n                    x_war.append(stats)\n                    y_war.append(row['WARP'])  # fallback to WARP\n                    hitter_names_war.append(warp_name)\n\n    print(f\"Successfully matched {len(x_warp)} hitters with 7 features (5 hitting + baserunning + defense)\")\n\n    # Handle pitcher data similarly\n    pitcher_warp_to_main = create_name_mapping(\n        pitcher_pred_data['Name'].tolist(),\n        pitcher_data['Pitchers'].tolist()\n    )\n    pitcher_warp_to_war = create_name_mapping(\n        pitcher_pred_data['Name'].tolist(),\n        war_values['Name'].tolist()\n    )\n\n    pitcher_stats = pitcher_data  # Already aggregated in clean_sorted_pitcher()\n\n    # Pitcher features & targets (keeping your original variable names)\n    a_warp, b_warp, a_war, b_war = [], [], [], []\n    pitcher_names_warp, pitcher_names_war = [], []\n\n    for index, row in pitcher_pred_data.iterrows():\n        warp_name = row['Name']\n        pitcher_match = pitcher_warp_to_main.get(warp_name)\n        if pitcher_match:\n            player_stats = pitcher_stats[pitcher_stats['Pitchers'] == pitcher_match]\n            if not player_stats.empty:\n                stats = player_stats[['IP','BB','K','HR','ERA']].values.flatten().tolist()\n                a_warp.append(stats)\n                b_warp.append(row['WARP'])\n                pitcher_names_warp.append(warp_name)\n                \n                # Try to get WAR value\n                war_match = pitcher_warp_to_war.get(warp_name)\n                if war_match:\n                    war_row = war_values[war_values['Name'] == war_match]\n                    if not war_row.empty and 'Primary WAR' in war_row.columns:\n                        a_war.append(stats)\n                        b_war.append(war_row['Primary WAR'].iloc[0])\n                        pitcher_names_war.append(warp_name)\n\n    print(f\"Successfully matched {len(a_warp)} pitchers\")\n\n    # Ensure we have data before splitting\n    if len(x_warp) == 0:\n        raise ValueError(\"No hitter data matched! Check your data files.\")\n    if len(a_warp) == 0:\n        raise ValueError(\"No pitcher data matched! Check your data files.\")\n\n    print(\"Data preparation completed successfully!\")\n    return (x_warp, y_warp, x_war, y_war, a_warp, b_warp, a_war, b_war,\n            hitter_names_warp, hitter_names_war, pitcher_names_warp, pitcher_names_war)"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "qfpwxt61qbq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "def prepare_train_test_splits():\n",
    "    (x_warp, y_warp, x_war, y_war, a_warp, b_warp, a_war, b_war,\n",
    "     hitter_names_warp, hitter_names_war, pitcher_names_warp, pitcher_names_war) = data_preparation()\n",
    "    \n",
    "    # Hitter splits\n",
    "    x_warp_train, x_warp_test, y_warp_train, y_warp_test, h_names_warp_train, h_names_warp_test = train_test_split(\n",
    "        x_warp, y_warp, hitter_names_warp, test_size=0.25, train_size=0.75, random_state=1\n",
    "    )\n",
    "    x_war_train, x_war_test, y_war_train, y_war_test, h_names_war_train, h_names_war_test = train_test_split(\n",
    "        x_war, y_war, hitter_names_war, test_size=0.25, train_size=0.75, random_state=1\n",
    "    )\n",
    "\n",
    "    # Pitcher splits\n",
    "    a_warp_train, a_warp_test, b_warp_train, b_warp_test, p_names_warp_train, p_names_warp_test = train_test_split(\n",
    "        a_warp, b_warp, pitcher_names_warp, test_size=0.25, train_size=0.75, random_state=1\n",
    "    )\n",
    "    \n",
    "    # Handle case where no pitcher WAR data is available\n",
    "    if len(a_war) > 0:\n",
    "        a_war_train, a_war_test, b_war_train, b_war_test, p_names_war_train, p_names_war_test = train_test_split(\n",
    "            a_war, b_war, pitcher_names_war, test_size=0.25, train_size=0.75, random_state=1\n",
    "        )\n",
    "    else:\n",
    "        # Use WARP data as fallback for pitcher WAR\n",
    "        a_war_train, a_war_test, b_war_train, b_war_test = a_warp_train, a_warp_test, b_warp_train, b_warp_test\n",
    "        p_names_war_train, p_names_war_test = p_names_warp_train, p_names_warp_test\n",
    "\n",
    "    print(\"Train/test splits completed!\")\n",
    "    return (x_warp_train, x_warp_test, y_warp_train, y_warp_test,\n",
    "            x_war_train, x_war_test, y_war_train, y_war_test,\n",
    "            a_warp_train, a_warp_test, b_warp_train, b_warp_test,\n",
    "            a_war_train, a_war_test, b_war_train, b_war_test,\n",
    "            h_names_warp_test, h_names_war_test, p_names_warp_test, p_names_war_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8l9xch9xs5u",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player Lookup and Analysis\n",
    "class ModelResults:\n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "        self.player_names = {}\n",
    "        \n",
    "    def store_results(self, model_name, player_type, metric_type, y_true, y_pred, player_names):\n",
    "        \"\"\"Store model results for later lookup\"\"\"\n",
    "        key = f\"{model_name}_{player_type}_{metric_type}\"\n",
    "        self.results[key] = {\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "            'player_names': player_names\n",
    "        }\n",
    "    \n",
    "    def lookup_player(self, player_name, model_name=None):\n",
    "        \"\"\"Look up a specific player's results across all models\"\"\"\n",
    "        results = []\n",
    "        search_name = player_name.lower()\n",
    "        \n",
    "        for key, data in self.results.items():\n",
    "            model, player_type, metric = key.split('_', 2)\n",
    "            \n",
    "            # Skip if specific model requested and doesn't match\n",
    "            if model_name and model.lower() != model_name.lower():\n",
    "                continue\n",
    "                \n",
    "            names = [name.lower() for name in data['player_names']]\n",
    "            \n",
    "            # Find matching player\n",
    "            for i, name in enumerate(names):\n",
    "                if search_name in name or name in search_name:\n",
    "                    actual = data['y_true'][i]\n",
    "                    predicted = data['y_pred'][i]\n",
    "                    error = abs(actual - predicted)\n",
    "                    error_pct = (error / abs(actual) * 100) if actual != 0 else float('inf')\n",
    "                    \n",
    "                    results.append({\n",
    "                        'model': model,\n",
    "                        'player_type': player_type,\n",
    "                        'metric': metric,\n",
    "                        'player_name': data['player_names'][i],\n",
    "                        'actual': actual,\n",
    "                        'predicted': predicted,\n",
    "                        'error': error,\n",
    "                        'error_pct': error_pct\n",
    "                    })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def display_player_results(self, player_name, model_name=None):\n",
    "        \"\"\"Display formatted results for a player\"\"\"\n",
    "        results = self.lookup_player(player_name, model_name)\n",
    "        \n",
    "        if not results:\n",
    "            print(f\"No results found for player: {player_name}\")\n",
    "            return\n",
    "            \n",
    "        print(f\"\\n=== RESULTS FOR {results[0]['player_name'].upper()} ===\")\n",
    "        \n",
    "        # Group by player type and metric\n",
    "        for player_type in ['hitter', 'pitcher']:\n",
    "            type_results = [r for r in results if r['player_type'] == player_type]\n",
    "            if not type_results:\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\n{player_type.upper()} PERFORMANCE:\")\n",
    "            \n",
    "            for metric in ['warp', 'war']:\n",
    "                metric_results = [r for r in type_results if r['metric'] == metric]\n",
    "                if not metric_results:\n",
    "                    continue\n",
    "                    \n",
    "                print(f\"\\n  {metric.upper()}:\")\n",
    "                print(f\"    {'Model':<15} {'Actual':<8} {'Predicted':<10} {'Error':<8} {'Error %':<8}\")\n",
    "                print(f\"    {'-'*55}\")\n",
    "                \n",
    "                for result in metric_results:\n",
    "                    print(f\"    {result['model']:<15} {result['actual']:<8.3f} {result['predicted']:<10.3f} \"\n",
    "                          f\"{result['error']:<8.3f} {result['error_pct']:<8.1f}%\")\n",
    "\n",
    "# Global results storage\n",
    "model_results = ModelResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uhve8ltg93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Regression Models (Linear, Lasso, ElasticNet) - OPTIMIZED\n",
    "def run_basic_regressions(data_splits=None):\n",
    "    # Get data once instead of recalculating\n",
    "    if data_splits is None:\n",
    "        data_splits = prepare_train_test_splits()\n",
    "    \n",
    "    (x_warp_train, x_warp_test, y_warp_train, y_warp_test,\n",
    "     x_war_train, x_war_test, y_war_train, y_war_test,\n",
    "     a_warp_train, a_warp_test, b_warp_train, b_warp_test,\n",
    "     a_war_train, a_war_test, b_war_train, b_war_test,\n",
    "     h_names_warp_test, h_names_war_test, p_names_warp_test, p_names_war_test) = data_splits\n",
    "\n",
    "    models = [\n",
    "        ('linear', LinearRegression()),\n",
    "        ('lasso', Lasso()),\n",
    "        ('elasticnet', ElasticNet())\n",
    "    ]\n",
    "    \n",
    "    for name, model in models:\n",
    "        print(f\"=== {name.upper()} REGRESSION ===\")\n",
    "        \n",
    "        # Train all variants efficiently in a loop\n",
    "        datasets = [\n",
    "            ('hitter', 'warp', x_warp_train, x_warp_test, y_warp_train, y_warp_test, h_names_warp_test),\n",
    "            ('hitter', 'war', x_war_train, x_war_test, y_war_train, y_war_test, h_names_war_test),\n",
    "            ('pitcher', 'warp', a_warp_train, a_warp_test, b_warp_train, b_warp_test, p_names_warp_test),\n",
    "            ('pitcher', 'war', a_war_train, a_war_test, b_war_train, b_war_test, p_names_war_test)\n",
    "        ]\n",
    "        \n",
    "        for player_type, metric, X_train, X_test, y_train, y_test, names_test in datasets:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            print_metrics(f\"{name} {player_type} {metric}\", y_test, y_pred)\n",
    "            plot_results(f\"{player_type} {metric} ({name})\", y_test, y_pred)\n",
    "            model_results.store_results(name, player_type, metric, y_test, y_pred, names_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w4gt6vz298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Models (KNN, Random Forest, XGBoost) - OPTIMIZED\n",
    "def run_advanced_models(data_splits=None):\n",
    "    # Get data once instead of recalculating\n",
    "    if data_splits is None:\n",
    "        data_splits = prepare_train_test_splits()\n",
    "    \n",
    "    (x_warp_train, x_warp_test, y_warp_train, y_warp_test,\n",
    "     x_war_train, x_war_test, y_war_train, y_war_test,\n",
    "     a_warp_train, a_warp_test, b_warp_train, b_warp_test,\n",
    "     a_war_train, a_war_test, b_war_train, b_war_test,\n",
    "     h_names_warp_test, h_names_war_test, p_names_warp_test, p_names_war_test) = data_splits\n",
    "\n",
    "    # Optimized model configurations with parallelization\n",
    "    models = [\n",
    "        ('knn', KNeighborsRegressor(n_neighbors=3, n_jobs=-1)),  # Use all CPU cores\n",
    "        ('randomforest', RandomForestRegressor(n_estimators=50, max_depth=8, random_state=1, n_jobs=-1)),  # Smaller, faster\n",
    "        ('xgboost', xgb.XGBRegressor(n_estimators=50, max_depth=4, learning_rate=0.1, random_state=1, n_jobs=-1))  # Optimized\n",
    "    ]\n",
    "    \n",
    "    for name, model in models:\n",
    "        print(f\"=== {name.upper()} ===\")\n",
    "        \n",
    "        datasets = [\n",
    "            ('hitter', 'warp', x_warp_train, x_warp_test, y_warp_train, y_warp_test, h_names_warp_test),\n",
    "            ('hitter', 'war', x_war_train, x_war_test, y_war_train, y_war_test, h_names_war_test),\n",
    "            ('pitcher', 'warp', a_warp_train, a_warp_test, b_warp_train, b_warp_test, p_names_warp_test),\n",
    "            ('pitcher', 'war', a_war_train, a_war_test, b_war_train, b_war_test, p_names_war_test)\n",
    "        ]\n",
    "        \n",
    "        for player_type, metric, X_train, X_test, y_train, y_test, names_test in datasets:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            print_metrics(f\"{name} {player_type} {metric}\", y_test, y_pred)\n",
    "            plot_results(f\"{player_type} {metric} ({name})\", y_test, y_pred)\n",
    "            model_results.store_results(name, player_type, metric, y_test, y_pred, names_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z2403amsbw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network (Keras/TensorFlow) - OPTIMIZED\n",
    "def run_neural_network(data_splits=None):\n",
    "    # Get data once instead of recalculating\n",
    "    if data_splits is None:\n",
    "        data_splits = prepare_train_test_splits()\n",
    "    \n",
    "    (x_warp_train, x_warp_test, y_warp_train, y_warp_test,\n",
    "     x_war_train, x_war_test, y_war_train, y_war_test,\n",
    "     a_warp_train, a_warp_test, b_warp_train, b_warp_test,\n",
    "     a_war_train, a_war_test, b_war_train, b_war_test,\n",
    "     h_names_warp_test, h_names_war_test, p_names_warp_test, p_names_war_test) = data_splits\n",
    "\n",
    "    # Scale features for neural network (critical for convergence)\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # More aggressive early stopping for faster training\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping( # pyright: ignore[reportAttributeAccessIssue]\n",
    "        monitor='val_loss',\n",
    "        patience=10,  # Reduced from 20\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    print(\"=== KERAS NEURAL NETWORK ===\")\n",
    "\n",
    "    datasets = [\n",
    "        ('hitter', 'warp', x_warp_train, x_warp_test, y_warp_train, y_warp_test, h_names_warp_test),\n",
    "        ('hitter', 'war', x_war_train, x_war_test, y_war_train, y_war_test, h_names_war_test),\n",
    "        ('pitcher', 'warp', a_warp_train, a_warp_test, b_warp_train, b_warp_test, p_names_warp_test),\n",
    "        ('pitcher', 'war', a_war_train, a_war_test, b_war_train, b_war_test, p_names_war_test)\n",
    "    ]\n",
    "    \n",
    "    for player_type, metric, X_train, X_test, y_train, y_test, names_test in datasets:\n",
    "        print(f\"Training Neural Network for {player_type} {metric}...\")\n",
    "        \n",
    "        # Scale features\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        model = create_keras_model(input_dim=len(X_train[0]), name=f\"{player_type}_{metric}\")\n",
    "        \n",
    "        # Split training data for validation\n",
    "        X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "            X_train_scaled, y_train, test_size=0.2, random_state=1\n",
    "        )\n",
    "        \n",
    "        # Optimized training - faster epochs and larger batches\n",
    "        history = model.fit(\n",
    "            X_train_split, y_train_split,\n",
    "            validation_data=(X_val_split, y_val_split),\n",
    "            epochs=50,  # Reduced from 100\n",
    "            batch_size=32,  # Increased from 16\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        y_pred = model.predict(X_test_scaled, verbose=0).flatten()\n",
    "        print_metrics(f\"Keras {player_type} {metric}\", y_test, y_pred)\n",
    "        plot_results(f\"{player_type} {metric} (Keras Neural Network)\", y_test, y_pred)\n",
    "        plot_training_history(history, f\"{player_type} {metric}\")\n",
    "        model_results.store_results(\"keras\", player_type, metric, y_test, y_pred, names_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exg9tdoeqrd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RUNNING ALL MODELS (OPTIMIZED) ===\n",
      "\n",
      "Preparing data once for all models...\n",
      "Loading and preparing data...\n",
      "Loaded data - Hitters: 361331, WARP hitters: 463, WAR: 1508\n",
      "Baserunning values: 0, Defensive values: 0\n",
      "Creating name mappings...\n"
     ]
    }
   ],
   "source": [
    "# Run All Models - OPTIMIZED\n",
    "def main():\n",
    "    print(\"=== RUNNING ALL MODELS (OPTIMIZED) ===\\n\")\n",
    "    \n",
    "    # 1. Prepare data ONCE for all models\n",
    "    print(\"Preparing data once for all models...\")\n",
    "    data_splits = prepare_train_test_splits()\n",
    "    \n",
    "    # 2. Pass data to all model functions to avoid recomputation\n",
    "    print(\"1. Basic Regression Models\")\n",
    "    run_basic_regressions(data_splits)\n",
    "    \n",
    "    print(\"\\n2. Advanced Models\")  \n",
    "    run_advanced_models(data_splits)\n",
    "    \n",
    "    print(\"\\n3. Neural Network\")\n",
    "    run_neural_network(data_splits)\n",
    "    \n",
    "    print(\"\\n=== ALL MODELS COMPLETED ===\")\n",
    "    print(\"\\nTo lookup a player's results, use:\")\n",
    "    print(\"model_results.display_player_results('Player Name')\")\n",
    "\n",
    "# Uncomment to run all models\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n8nq5j8n2ko",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player Lookup Examples\n",
    "# After running models, use these commands to look up specific players:\n",
    "\n",
    "# Example usage:\n",
    "# model_results.display_player_results(\"Mike Trout\")\n",
    "# model_results.display_player_results(\"Gerrit Cole\") \n",
    "# model_results.display_player_results(\"Mookie Betts\", \"linear\")  # Only linear model results\n",
    "\n",
    "# You can also get raw results:\n",
    "# trout_results = model_results.lookup_player(\"Mike Trout\")\n",
    "# print(trout_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}